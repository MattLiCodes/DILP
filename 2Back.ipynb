{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56c692a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from src.core import Term, Atom\n",
    "from src.ilp import Language_Frame, Program_Template, Rule_Template\n",
    "from src.dilp import DILP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a3c0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = [\n",
    "    Atom([Term(False, '(A, 1)'), Term(False, '(B, 2)')], 'succ'),\n",
    "    Atom([Term(False, '(B, 2)'), Term(False, '(C, 3)')], 'succ'),\n",
    "    Atom([Term(False, '(C, 3)'), Term(False, '(D, 4)')], 'succ'),\n",
    "    Atom([Term(False, '(D, 4)'), Term(False, '(E, 5)')], 'succ'),\n",
    "    Atom([Term(False, '(E, 5)'), Term(False, '(D, 6)')], 'succ'),\n",
    "    Atom([Term(False, '(D, 6)'), Term(False, '(C, 7)')], 'succ'),\n",
    "    Atom([Term(False, '(C, 7)'), Term(False, '(C, 8)')], 'succ'),\n",
    "    Atom([Term(False, '(C, 8)'), Term(False, '(E, 9)')], 'succ'),\n",
    "    Atom([Term(False, '(E, 9)'), Term(False, '(C, 10)')], 'succ'),\n",
    "    Atom([Term(False, '(C, 10)'), Term(False, '(E, 11)')], 'succ'),\n",
    "\n",
    "    Atom([Term(False, '(D, 4)'), Term(False, '(D, 6)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(C, 3)'), Term(False, '(C, 7)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(C, 3)'), Term(False, '(C, 8)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(C, 3)'), Term(False, '(C, 10)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(C, 7)'), Term(False, '(C, 8)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(E, 5)'), Term(False, '(E, 9)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(C, 7)'), Term(False, '(C, 10)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(C, 8)'), Term(False, '(C, 10)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(E, 5)'), Term(False, '(E, 11)')], 'sameLetter'),\n",
    "    Atom([Term(False, '(E, 9)'), Term(False, '(E, 11)')], 'sameLetter')\n",
    "]\n",
    "predicates = {\n",
    "    Atom([Term(True, 'X_0'), Term(True, 'X_1')], 'succ'),\n",
    "    Atom([Term(True, 'X_0'), Term(True, 'X_1')], 'sameLetter'),\n",
    "    Atom([Term(True, 'X_0'), Term(True, 'X_1')], '2Back')\n",
    "}\n",
    "\n",
    "constants = {'(A, 1)', '(B, 2)', '(C, 3)', '(D, 4)', '(E, 5)', '(D, 6)', '(C, 7)', \n",
    " '(C, 8)', '(E, 9)', '(C, 10)', '(E, 11)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c56c29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples = [\n",
    "    Atom([Term(False, '(E, 5)'), Term(False, '(D, 6)')], '2Back'),\n",
    "    Atom([Term(False, '(E, 9)'), Term(False, '(C, 10)')], '2Back'),\n",
    "    Atom([Term(False, '(C, 10)'), Term(False, '(E, 11)')], '2Back')\n",
    "]\n",
    "\n",
    "negative_examples = [\n",
    "    Atom([Term(False, '(A, 1)'), Term(False, '(B, 2)')], '2Back'),\n",
    "    Atom([Term(False, '(B, 2)'), Term(False, '(C, 3)')], '2Back'),\n",
    "    Atom([Term(False, '(C, 3)'), Term(False, '(D, 4)')], '2Back'),\n",
    "    Atom([Term(False, '(D, 4)'), Term(False, '(E, 5)')], '2Back'),\n",
    "    Atom([Term(False, '(D, 6)'), Term(False, '(C, 7)')], '2Back'),\n",
    "    Atom([Term(False, '(C, 7)'), Term(False, '(C, 8)')], '2Back'),\n",
    "    Atom([Term(False, '(C, 8)'), Term(False, '(E, 9)')], '2Back')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "260cbc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target predicate template\n",
    "term_x_0 = Term(True, 'X_0')\n",
    "term_x_1 = Term(True, 'X_1')\n",
    "p_e = list(predicates)\n",
    "p_a = [Atom([term_x_0, term_x_1], '2Back')]\n",
    "target = Atom([term_x_0, term_x_1], '2Back')\n",
    "\n",
    "# instructions\n",
    "p_a_rule = (Rule_Template(4, False), Rule_Template(4, False))\n",
    "target_rule = (Rule_Template(4, False), Rule_Template(4, False))\n",
    "rules = {p_a[0]: p_a_rule, target: target_rule}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5c6d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang frame and program template\n",
    "language_frame = Language_Frame(target, p_e, constants)\n",
    "program_template = Program_Template(p_a, rules, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1bcb9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_template.arity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6d50301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Inference\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Inference Complete\n",
      "Performing Inference\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Inference Complete\n",
      "--------------------\n",
      "step 0 loss is 6.907755374908447\n",
      "Performing Inference\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Inference Complete\n",
      "2Back((D, 6),(C, 7)) Expected: 0 0.000\n",
      "2Back((E, 9),(C, 10)) Expected: 1 0.000\n",
      "2Back((C, 8),(E, 9)) Expected: 0 0.000\n",
      "2Back((A, 1),(B, 2)) Expected: 0 0.000\n",
      "2Back((D, 4),(E, 5)) Expected: 0 0.000\n",
      "2Back((C, 10),(E, 11)) Expected: 1 0.000\n",
      "2Back((E, 5),(D, 6)) Expected: 1 0.000\n",
      "2Back((B, 2),(C, 3)) Expected: 0 0.000\n",
      "2Back((C, 7),(C, 8)) Expected: 0 0.000\n",
      "2Back((C, 3),(D, 4)) Expected: 0 0.000\n",
      "----------------------------\n",
      "2Back(X_0,X_1)\n",
      "2Back(X_0,X_1) -> 2Back(X_0,X_2),sameLetter(X_1,X_0)\n",
      "2Back(X_0,X_1) -> succ(X_1,X_0),2Back(X_2,X_2)\n",
      "----------------------------\n",
      "--------------------\n",
      "\n",
      "Performing Inference\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Inference Complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run dilp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dilp \u001b[38;5;241m=\u001b[39m DILP(language_frame, atoms, positive_examples, negative_examples, program_template)\n\u001b[0;32m----> 3\u001b[0m dilp\u001b[38;5;241m.\u001b[39mtrain(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m)\n",
      "File \u001b[0;32m~/horizon/repos/neurosym/DILP-Core/src/dilp/dilp.py:128\u001b[0m, in \u001b[0;36mDILP.train\u001b[0;34m(self, steps, name)\u001b[0m\n\u001b[1;32m    125\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mAdamOptimizer(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m--> 128\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad()\n\u001b[1;32m    129\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__all_variables()),\n\u001b[1;32m    130\u001b[0m                               global_step\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mget_or_create_global_step())\n\u001b[1;32m    131\u001b[0m     loss_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/horizon/repos/neurosym/DILP-Core/src/dilp/dilp.py:169\u001b[0m, in \u001b[0;36mDILP.grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         regularization \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(input_tensor\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msqrt(weights)\n\u001b[1;32m    167\u001b[0m                                         ) \u001b[38;5;241m*\u001b[39m weight_decay\n\u001b[1;32m    168\u001b[0m     loss_value \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m regularization \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__all_variables())\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mgradient(loss_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__all_variables())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:1066\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1061\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1062\u001b[0m           output_gradients))\n\u001b[1;32m   1063\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1066\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m imperative_grad\u001b[38;5;241m.\u001b[39mimperative_grad(\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape,\n\u001b[1;32m   1068\u001b[0m     flat_targets,\n\u001b[1;32m   1069\u001b[0m     flat_sources,\n\u001b[1;32m   1070\u001b[0m     output_gradients\u001b[38;5;241m=\u001b[39moutput_gradients,\n\u001b[1;32m   1071\u001b[0m     sources_raw\u001b[38;5;241m=\u001b[39mflat_sources_raw,\n\u001b[1;32m   1072\u001b[0m     unconnected_gradients\u001b[38;5;241m=\u001b[39munconnected_gradients)\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[38;5;241m.\u001b[39m_tape,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str(unconnected_gradients\u001b[38;5;241m.\u001b[39mvalue))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:148\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/math_grad.py:1587\u001b[0m, in \u001b[0;36m_MaximumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;129m@ops\u001b[39m\u001b[38;5;241m.\u001b[39mRegisterGradient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_MaximumGrad\u001b[39m(op: ops\u001b[38;5;241m.\u001b[39mOperation, grad):\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns grad*(x >= y, x < y) with type of grad.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1587\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MaximumMinimumGrad(op, grad, math_ops\u001b[38;5;241m.\u001b[39mgreater_equal)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/math_grad.py:1581\u001b[0m, in \u001b[0;36m_MaximumMinimumGrad\u001b[0;34m(op, grad, selector_op)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1580\u001b[0m   gy \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mwhere_v2(xmask, zeros, grad)\n\u001b[0;32m-> 1581\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ReduceGradientArgs(x, y, gx, gy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/math_grad.py:144\u001b[0m, in \u001b[0;36m_ReduceGradientArgs\u001b[0;34m(x, y, gx, gy)\u001b[0m\n\u001b[1;32m    142\u001b[0m   bx, by \u001b[38;5;241m=\u001b[39m SmartBroadcastGradientArgs(x, y)\n\u001b[1;32m    143\u001b[0m   gx \u001b[38;5;241m=\u001b[39m _ReduceGradientArg(gx, bx)\n\u001b[0;32m--> 144\u001b[0m   gy \u001b[38;5;241m=\u001b[39m _ReduceGradientArg(gy, by)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gx, gy\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/math_grad.py:134\u001b[0m, in \u001b[0;36m_ReduceGradientArg\u001b[0;34m(grad, shape_axes_must_reduce)\u001b[0m\n\u001b[1;32m    129\u001b[0m shape, axes, must_reduce \u001b[38;5;241m=\u001b[39m shape_axes_must_reduce\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m must_reduce:\n\u001b[1;32m    131\u001b[0m   \u001b[38;5;66;03m# Applying keepdims=True in presence of unknown axes opens up some\u001b[39;00m\n\u001b[1;32m    132\u001b[0m   \u001b[38;5;66;03m# opportunities for optimizations. For example, _SumGrad below won't have to\u001b[39;00m\n\u001b[1;32m    133\u001b[0m   \u001b[38;5;66;03m# emit extra ops to recover reduced indices for broadcasting.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m   grad \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mreduce_sum(grad, axes, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m   grad \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mreshape(grad, shape)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py:2209\u001b[0m, in \u001b[0;36mreduce_sum\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmath.reduce_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   2148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce_sum\u001b[39m(input_tensor, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2149\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the sum of elements across dimensions of a tensor.\u001b[39;00m\n\u001b[1;32m   2150\u001b[0m \n\u001b[1;32m   2151\u001b[0m \u001b[38;5;124;03m  This is the reduction operation for the elementwise `tf.math.add` op.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;124;03m  @end_compatibility\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[1;32m   2210\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py:2221\u001b[0m, in \u001b[0;36mreduce_sum_with_dims\u001b[0;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce_sum_with_dims\u001b[39m(input_tensor,\n\u001b[1;32m   2214\u001b[0m                          axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2215\u001b[0m                          keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2216\u001b[0m                          name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2217\u001b[0m                          dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2218\u001b[0m   keepdims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(keepdims)\n\u001b[1;32m   2219\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _may_reduce_to_scalar(\n\u001b[1;32m   2220\u001b[0m       keepdims, axis,\n\u001b[0;32m-> 2221\u001b[0m       gen_math_ops\u001b[38;5;241m.\u001b[39m_sum(input_tensor, dims, keepdims, name\u001b[38;5;241m=\u001b[39mname))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py:12372\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m  12370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m  12371\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m> 12372\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m  12373\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, \u001b[38;5;28minput\u001b[39m, axis, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeep_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, keep_dims)\n\u001b[1;32m  12374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m  12375\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run dilp\n",
    "dilp = DILP(language_frame, atoms, positive_examples, negative_examples, program_template)\n",
    "dilp.train(steps=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88455009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
